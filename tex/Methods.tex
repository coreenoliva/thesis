\chapter{Method}
\label{chpt: method}

Chapter \ref{chpt: method} outlines all the procedures and methods that were undertaken to conduct the investigations and experiments. 

\section{Algorithm Usage}
Various algorithms and supplied scripts were used throughout the stages of the method. This section will describe the usage and the outputs of each algorithm.
\subsection{NIfTI} 
\label{sect:nifti}
The NIfTI MATLAB package is used to handle NIfTI formatted images. This package allows for functions such as:
\begin{itemize}
	\item Load NIfTI files
	\item Make an image into a NIfTI file
	\item Save NIfTI file
\end{itemize}

The functions mentioned above have the following definitions.
\begin{lstlisting}
%Load nii usage
nii = load_nii(filename, [img_idx], [dim5_idx], [dim6_idx], ...
			[dim7_idx], [old_RGB], [tolerance], [preferredForm])
			
%Make nii usage
nii = make_nii(img, [voxel_size], [origin], [datatype],...
 			[description])

%Save nii usage
save_nii(nii, filename, [old_RGB])
\end{lstlisting}

\subsection{Random Forest} 
The Random Forest algorithm for MATLAB has both classification and regression scripts for training and prediction functions. Regression and classification functions both take in the same parameters. 
\subsubsection{Training}
\label{sect:rf_training}
The classification and regression training functions are defined as:
\begin{lstlisting}
%RF Classification training
function model = classRF_train(X,Y,ntree,mtry, extra_options)

%RF Regression training
function model = regRF_train(X,Y,ntree,mtry, extra_options)
\end{lstlisting}
\medskip
Where X is the data matrix, Y are the target values, ntree is the number of trees to grow and mtry represents the number of remaining predictor values to use. mtry has been set to 20 all throughout. Extra options such as importance and proximity calculations have been utilised. The importance option provides an estimate on the level of contribution of each feature.
\begin{lstlisting}
%Set up of RF training parameters
mtry = 20;
extra_options.importance = 1;
extra_options.proximity = 1;
\end{lstlisting}
The output of the training functions returns a model which is a struct to be used for creating predictions. This struct contains the following information:
\begin{itemize}
	\item Importance matrix
	\item Standard errors of the importance measure
	\item Local importance
	\item Number of trees grown
	\item Number of predictors sampled at each node
	\item Number of times the cases have been 'out of bag'
	\item Proximity measures among the input
	\item Out of bag error rate
\end{itemize}

\subsubsection{Prediction}
\label{sect:rf_testing}
Random Forest prediction has corresponding classification and regression functions. 
\begin{lstlisting}
%RF Classification prediction
function [Y_hat votes] = classRF_predict(X,model, extra_options)

%RF Regression prediction
function Y_hat = regRF_predict(X,model)
\end{lstlisting}
\medskip
Where X is the testing data, and the model is the Random Forest model obtained from training. The classification prediction function takes in extra parameters which was not utilised in this thesis.
\\[1\baselineskip]
For outputs of the prediction Y\_hat is the vector containing predictions on X. Specifically for classification, the output votes contains the non-normalised weights of the model.

\subsection{SLICO Superpixels}
\label{sect:slico}
The SLICO algorithm is used to produce superpixel patches from an image. The supplied C code had to be compiled in order to use the functions.
\\[1\baselineskip]
 The SLICO superpixels function requires two input parameters: image, and the number of required superpixels. The outputs are: the labels and the number of produced superpixels. An example usage can be seen below. 
\begin{lstlisting}
[labels, numlabels] = slicomex(img,200);
\end{lstlisting}
\subsection{Feature Extraction}
\label{sect:calcFeature}
The same features were extracted throughout the thesis. The list of features extracted can be referred to in \ref{sect:features}. The feature calculation function has the following usage:
\begin{lstlisting}
%Feature calculation usage
function F=calcFeature(S,I,f)
\end{lstlisting}
\medskip
Where S is the labelled image or segmentation, I is the image to calculate features on, f holds the features to be calculated. The features were initialised for extraction as seen below.
\begin{lstlisting}
%Intialise cell with features
cFG=0;
tempf={};
tempf{cFG+1}.name='Intensity';tempf{cFG+1}.par=[];cFG=cFG+1;
tempf{cFG+1}.name='Gradient';tempf{cFG+1}.par=[];cFG=cFG+1;
tempf{cFG+1}.name='GLCM';tempf{cFG+1}.par=[];cFG=cFG+1;
tempf{cFG+1}.name='Entropy';tempf{cFG+1}.par=[];cFG=cFG+1;
\end{lstlisting}
\medskip
The output of the feature extraction is a cell containing the features which was accessed as follows:
\begin{lstlisting}
%Accessing features from output
features = calculate_features.fea;
\end{lstlisting}

\pagebreak
\section{General Approach}
Producing a segmentation approach was tackled in two main phases; the training and testing stage. The overall general process can be seen below in figure \ref{fig:training_testing_flow}. For each of these stages, numerous experiments were conducted to find optimal parameters and procedures. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{fig/training_testing.png}
\caption{General flow chart of training and testing method.}
\label{fig:training_testing_flow}
\end{figure}

\section{Pre-Training and Pre-Testing}
\label{sect:pre}
The loading of images, superpixel patch production and feature extraction need to be done prior to the Random Forest processing for both training and testing phases. Both phases have similar aspects such as environment set up, image loading and preparation, superpixel generation and feature extractions - pre-training and pre-testing phases. Figure \ref{fig:prestages} gives an outline as to the process that occur in these initial phases. The preparation stages are run iteratively for each training or testing image and saved in a struct.

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{fig/prestages.png}
\caption{Process of pre-training and pre-testing stages.}
\label{fig:prestages}
\end{figure}

\subsection{Environment}
An environment set up and initialisation was first done. The environment requires the paths to image directories, source functions, libraries and output directories. The environment is set up the same way for both training and testing phases with their corresponding output directories. The file contents for image directories were outputted for ease of access when loading them.  This is shown below with pseudo directories.

\begin{lstlisting}[escapeinside={(*}{*)}]
%% Initalise Directories 
%Image paths
addpath('Image paths');

%Library paths
addpath('library paths');

%Create list of all files in each image directory

% list all image files
filelist=dir('image_path'); 
% list all bone label files
labellist=dir('label_path');
%list all mask files 
masklist=dir('mask_path'); 
\end{lstlisting}


\subsection{Loading Images} 
Both training and testing phases require the training set of bone images and their corresponding labelled images and masks. These 3D images of size $[X \times Y \times Z]$ are loaded using the NIfTI tools package \cite{ref:nifti_1} for MATLAB. Pseudo directories amongst code shown below as an example. 
\begin{lstlisting}
%Index filelist for image
get_image = fullfile('image_path', filelist(i).name);
get_label = fullfile('label_path', labellist(i).name);
get_mask =  fullfile('mask_path', masklist(i).name);
    
%Loading nii bone, label, and mask
load_image = load_nii(get_image);
load_label = load_nii(get_label);
load_mask = load_nii(get_mask); 

%Obtain .img of bone, label, and mask
full_img = load_image.img;
full_label = load_label.img;
full_mask = load_mask.img;
\end{lstlisting}

\bigskip
The middle 2D slice of the bone, label and mask images are obtained by calculating the middle index along the z dimension producing a $[X \times Y]$ matrix. It should also be noted that the image intensities are scaled to be positive values for compatibility with superpixel generation and feature calculation.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{fig/imagesize.png}
\caption{Matrix sizes for 2D bone, label and mask images.}
\label{mat:image}
\end{figure}

\begin{lstlisting}
%Calculating the middle index
mid = size(full_label,3)/2;

%Obtaining middle image
img = full_img(:,:, mid);
min_img = min(img(:));
img = img+abs(min_img);
img_nii = make_nii(img);

%Obtaining middle label
label = full_label(:,:, mid );
min_label = min(label(:));
label = label + abs(min_label);
label_nii = make_nii(label);

%Obtaining middle mask
mask = full_mask(:,:, mid);
min_mask = min(mask(:));
\end{lstlisting}



\subsection{Patch Generation and Extraction}
A superpixel lattice is generated for the 2D bone image slice using the SLIC superpixel algorithm. 

\begin{lstlisting}
%Generate superpixel
[labels, numlabels] = slicomex(img, N_superpixels);
imlabels = imagesc(labels);
pixels = imlabels.CData;
\end{lstlisting}
\bigskip

The colour labels as seen in figure \ref{fig:colourmap} is the output of the generated superpixel lattice where each colour represents a patch generated. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{fig/colourmap.png}
\caption{Colour map produced from SLICO superpixel.}
\label{fig:colourmap}
\end{figure}

The image coordinates for each patch can then be calculated using the matrix produced - called pixels in the example code provided. This matrix contains the prescribed colour label for each element in the image and is the same size as the image.

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{fig/pixelssize.png}
\caption{Pixel matrix size.}
\label{mat: pixel}
\end{figure}


Patch extraction iterating through the total number of patches created and translating its linear index to the image subscripts from the pixels matrix. Coordinates are then used to extract the superpixel patch from the bone image and the same coordinates are used to extract the labelled image patch. The patches that are extracted differ in size will be of dimension $[r \times c]$ where r and c are just subsets of the image size $[X \times Y]$.
\\[1\baselineskip]
Each patch is checked against the mask image and removed if it is located outside the mask, ie. when the mask is 0. Patches are then stored in corresponding bone and label cells.

\begin{figure}[H]
    \centering
    \subfloat[Matrix size of patch.]{{\includegraphics[width=5cm]{fig/matpatch.png} }}
    \qquad
    \subfloat[Cell sizes to store patches]{{\includegraphics[width=5cm]{fig/patchcell.png} }}
    \caption{Patch matrix and patch cell sizes.}%
    \label{mat:patch_cell}
\end{figure}


\begin{lstlisting}
%Initialise patch storage
patches = cell(numlabels, 1); %Bone patches
label_patches = cell(numlabels, 1); %Label patches

%Extract patches
for count_pixels = 1:numlabels
    [rows cols] = ind2sub(size(pixels), ...
        find(pixels == count_pixels - 1));
    if (find(mask(rows, cols) == 0) ~= 0 ) %Discard outside mask
        patches{count_pixels} = 0; 
    else
        patches{count_pixels} = img(rows, cols);
    end
    label_patches{count_pixels} = label(rows, cols);
end
\end{lstlisting} 
\bigskip
Figure \ref{fig: superpixel} below gives a visual on how the superpixel lattice appears over the training image. The lattice image produced is purely just for visual aid and does not contribute to the method. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.65]{fig/lattice.png}
\caption{Superpixel Lattice Overlay.}
\label{fig: superpixel}
\end{figure}
\subsection{Feature Extraction}
Features are extracted from the bone patches based on when the label patch contains bone. The features extracted were listed in \ref{sect:features} and the set up to prepare the feature extractions was outlined in \ref{sect:calcFeature}. Once the features were calculated, they are saved in a matrix. 
\begin{lstlisting}
%Calculating features
calculate_features = calcFeature(label_patches{num_patches},...
					patches{num_patches},tempf);

%Extracting features
temp = calculate_features.fea;

%Saving features in feature matrix
features(num_patches, 1:length(temp)) = temp;
\end{lstlisting}
\bigskip
Once all the features of all the patches were calculated, this produced a matrix of size $[\textrm{number of patches} \times 25]$, where each row represented each feature. Note that this matrix is only for 1 image. 
\\[1\baselineskip]
Mixed patches that have bone and non-bone produce features that go to negative infinity (NaN on Matlab). This becomes invalid to be used with the Random Forest training and testing functions in the later stages. To address this issue, the features which are produced as negative infinity are just re-written to be zeros. 
\begin{lstlisting}
%Features that go to NaN set to 0
nan = find(isnan(features));
[nanrow, nancol] = ind2sufb(size(features), nan);
features(nanrow, nancol) = 0;
\end{lstlisting}

\subsection{Target Vector Creation}
The final process of the preparation stages is to produce a target vector based off the corresponding label for the current image. For training, the target vector was required for Random Forest training. For the testing phase, the target vector was used to determine and analyse the accuracy of the predictions. Although the target vector was used differently by the training and testing phases, they are created the same way in the preparation stage so as to minimise computations. The size of the target vector is $[1 \times \textrm{number of patches}$. 
\\[1\baselineskip]
As superpixel patches are a cluster of individual pixels, there may be patches that contain both bone and non-bone matter. If the patch contains any bone, it is labelled as bone, else the patch has to have no bone at all to be classified as non-bone. Bones are labelled as 1's and non bone's as 0's as outlined in the process flowchart in figure \ref{fig:targetvectorflow}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{fig/targetvectorflow.png}
\caption{Flowchart of processes to produce target vector.}
\label{fig:targetvectorflow}
\end{figure}
\bigskip
\bigskip
\begin{lstlisting}
%% Producing Target Vector
for num_patches = 1:numlabels %Iterate through number of labels
    if sum(label_patches{num_patches}) == 0
        target(num_patches, 1) = 0;
    else 
        target(num_patches, 1) = 1;
    end
end
\end{lstlisting}

\section{Training Phase} 
\label{sect: trainstage}
The training stage as seen in \ref{fig:training_testing_flow} comes after the pre-training stage and requires the struct that was produced. Figure \ref{fig:trainingflow} outlines a detailed process of the training stage. The features extracted per image along with its target matrices need to compiled into one training feature matrix and target training matrix. The training feature matrix is then normalised and put through the Random Forest algorithm which outputs a learnt model. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{fig/training_flow.png}
\caption{Flowchart of process of training stage.}
\label{fig:trainingflow}
\end{figure}
\todo{change struct to cell}
\subsection{Compiling Random Forest Input Parameters}
The pre-training stage was performed iteratively for each training image and saved in a data cell. The data cell contained the following information: 
\begin{itemize}
	\item Number of patches produced.
	\item Matrix containing each pixels' prescribed colour label for patches.
	\item Cell containing all the image patches that were extracted.
	\item Cell containing all the corresponding label patches.
	\item Feature matrix for each image.
	\item Target vector for each image. 
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{fig/datacell.png}
\caption{Data cell used to store information extracted from pre-training stage.}
\label{mat:data}
\end{figure}

The Random Forest training function requires a matrix of all the training features, $[\textrm{M} \times \textrm{Features}]$, and a corresponding training target, $[\textrm{M}\times 1]$. Where M represents the total number of training examples - i.e. the total number of patches. Each of these features are stored individually per image in the data cell. These need to be concatenated to produce the required training matrices as seen in figure \ref{mat:trainmat}. 

\begin{lstlisting}
%Intialising training_features and training_target
training_features = 0;
training_target = 0;

%Iterate through number of images
for i = 1:number_of_training_images
   temp = data{i}.fea; %Get features for image i
   temptarget = data{i}.target; %Get targets for image i

	%Setting up first row   
   if training_features == 0
       training_features = temp;
   elseif training_target == 0
       training_target = temptarget;
   else
    if temp == 0 %No features calculated, skipping..
        continue
    end
    
    %Concatenate stored features and targets to 
    %		previous iteration.
    training_features = vertcat(training_features, temp);
    training_target = vertcat(training_target, temptarget);
   end
end
\end{lstlisting}


\begin{figure}[H]
    \centering
    \subfloat[Size of Training Matrix.]{{\includegraphics[width=6cm]{fig/mattraining.png} }}
    \qquad
    \subfloat[Size of Target Training Matrix]{{\includegraphics[width=5cm]{fig/targettrainmat.png} }}
    \caption{Size of the required matrices for training.}%
    \label{mat:trainmat}
\end{figure}

\subsection{Normalisation}
The features extracted can tend to differ depending on the image or type of feature being extracted.  The training matrix is then normalised to in order to have all properties relative to each other and within the same scale and distribution.  This was done using a supplied script, choosing to normalising between 0.009 to 0.999. The normalisation was done column-by-column.
\\[1\baselineskip]
\begin{lstlisting}
%Normalizing training features 
for i = 1:number_of_features; %Iterate through each column
    temp = training_features(:,i);
    training_features(:,i) = normalizetorange(temp,0.001,0.999);
end
\end{lstlisting}

\subsection{Random Forest Training}
The normalised training matrix and it's corresponding target matrix can now be used to build a model. This was done simply just like the usage shown in \ref{sect:rf_training}. Example code is shown below to follow the rest of the example pseudo code for both classification and regression.

\begin{lstlisting}
%Setup RF Parameters
no_trees = number_of_trees;
mtry = 20;
extra_options.importance = 1;
extra_options.proximity = 1;

%RF regression train
model = regRF_train(training_features, training_target,...
		 no_trees, mtry, extra_options);
\end{lstlisting}
\bigskip
The output produces a model that can be used to make predictions, which is done in the testing phase of the segmentation scheme. 
\section{Testing Phase}
\label{sect: teststage}

The testing phase is compromised of many stages and processes as highlighted in the flowchart in \ref{fig:test_flow}. The processes within the pre-testing phase were outlined earlier in \ref{sect:pre}. However, the pre-testing phase is repeated numerous times for the number of resolutions required. The multi-resolution stage includes the prediction with the use of the model produced during training. Thresholding is performed on the prediction based on the current level of resolution. Once the multi-resolution patch extraction and predictions are complete, the results are then mapped onto an image to produce an initial segmentation. A morphological opening process is  then conducted on this image to produce the final segmentation. Finally, the accuracies are calculated based on the predicted output image and the manual segmented image that was processed in the pre-testing phase.

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{fig/test_flow.png}
\caption{Flowchart of testing processes.}
\label{fig:test_flow}
\end{figure}

\subsection{Multi-Resolution} 
The multi-resolution stage requires the model produced in the training phase and the processing and patch and feature extraction of the test bone, label and mask images. The main idea of the multi-resolution process is to first make predictions based on larger patches, discard patches that do not contain bone and re-do the process with smaller and smaller patches to produce a refined segmentation.  The final method uses two levels of resolution.The levels of resolution are defined by the number of superpixels and the corresponding threshold values. 
\\[1\baselineskip]
Once the initial patch and feature extraction has been conducted, the Random Forest can then make predictions on this data. The Random Forest testing usage was described in \ref{sect:rf_testing}.Below is the usage within this process. 
\begin{lstlisting}
%RF regression prediction
 prediction_labels = regRF_predict(test_features, models.model);
 prediction_labels = 1 - prediction_labels;
\end{lstlisting}
\bigskip
The feature matrix ($test\_features$) is the feature extraction matrix and the prediction labels matrix is the output vector with a regression value for each prediction. It was found during testing that the prediction matrix was needed to be inverted in order to obtain the correct polarity in results.

\begin{figure}[H]
    \centering
    \subfloat[Size of Testing Feature Matrix.]{{\includegraphics[width=6cm]{fig/testfeaturematrix.png} }}
    \qquad
    \subfloat[Size of Prediction Labbels Matrix.]{{\includegraphics[width=5cm]{fig/predictionlabelmat.png} }}
    \caption{Size of the required matrix for testing and output matrix.}%
    \label{mat:testmat}
\end{figure}

The prediction labels matrix contains the regression prediction for each patch that was extracted. The values of the regression range from probabilities of 0 to 1; 0 being whole patch non-bone and 1 being whole patch is bone. If a patch is non-bone, the corresponding image will also be set to 0 so that it will not be considered in the next resolutions' patch extraction and prediction. By minimising the amount of mixed patches, the result will be a more accurate and refined segmentation. 
\\[1\baselineskip]
 A threshold is used to determine at which probability the patch is considered a bone. This threshold was selected and verified during testing. Figure \ref{fig:thresh} shows the processes of thresholding the regression predictions.

\begin{figure}[H]
\centering
\includegraphics[scale = 0.8]{fig/threshold.png}
\caption{Threshold process flowchart.}
\label{fig:thresh}
\end{figure}

\begin{lstlisting}
for i = 1:number_of_patches 
	%Obtain coordinates in test image for patch
    [row col] = ind2sub(size(test_pixels), ...
    			find(test_pixels == i-1)); 
    
       if  prediction_labels(i) < threshold  %Not bone
            test_img(row, col) = 0; 
            prediction_labels(i) = 0;
       end 
end
\end{lstlisting}
\subsection{Post Processing}
Once the multi-resolution process of classifying patches to bone or non-bone was completed, the predicted patches then needed to be translated into 2D image form.
\\[1\baselineskip]
Each patch is iterated through and coordinates within the image are obtained. The patch prediction is then assigned to the pixels at these coordinates. Overall, bone pixels were represented with 1's and non-bone pixels represented by 0's. The process is stepped through below in figure \ref{fig:mapimage}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{fig/mapimage.png}
\caption{Process of mapping prediction onto segmentation image.}
\label{fig:mapimage}
\end{figure}

\begin{lstlisting}
%Intialising classification image matrix
classification = zeros(size(test_pixels,1),...
	 size(test_pixels,2));

for i = 1:number_of_patches
    [row col] = ind2sub(size(test_pixels),...
    		find(test_pixels == i-1));
    if prediction_labels(i) ~= 0
        classification(row, col) = 1;
    else
        classification(row, col) = prediction_labels(i);
    end
end
\end{lstlisting}
\bigskip
Once the image has been mapped, the segmentation is further refined with morphology operations. The final method uses an opening operation on the image. This was simply done by defining the structural element and then using Matlab's opening function.

\begin{lstlisting}
%Morphology Opening image
structural_element = strel('disk', 4);
classification = imopen(classification, str_dil)
\end{lstlisting}

\subsection{Accuracy Calculation}
The performance of the produced segmentation result is compared to the test images' corresponding labelled image. The performances are calculated with respect to the patch classification accuracy and the pixel accuracy. The patch performance is determined by how well the model has correctly classified a patch. The image performance looks at how well the overall process  has been able to correctly classify each pixel. 
\\[1\baselineskip]
Scripts were devised for both patch and image performance quantification to output the following:
\begin{enumerate}
	\item Accuracy
	\item Sensitivity
	\item Specificity
	\item True Positive
	\item True Negative
	\item False Positives
	\item False Negatives
	\item Confusion Matrix
\end{enumerate}
The performance script of the patch segmentation requires the prediction label and target label for each patch. Each patch is iterated through and classifications are checked against the target label to determine its statistic.  The total number of positive patches are summed in order to calculate the rates to quantify the results as a percentage. The process can be seen in \ref{fig: accuracypatch}.
\\[1\baselineskip]
Similar to the patch performance script, the image performance script requires the whole result segmentation and the labelled image. Each pixel is iterated through using a double for-loop as seen in figure \ref{fig: accuracyimage}, so as to index to the pixel element in the 2D matrix. The pixels are compared and the statistics are tallied in order to produce the required rates listed above.

\begin{figure}[H]
\centering
\includegraphics[width = 15cm]{fig/accuracypatch.png}
\caption{Flowchart of patch accuracy script.}
\label{fig: accuracypatch}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width = 15cm]{fig/accuracyimage.png}
\caption{Flowchart of image accuracy script.}
\label{fig: accuracyimage}
\end{figure}

\section{Parameter and Process Testing}
Numerous tests were conducted in order to determine the optimal parameters and order of processes.  This process was split into two sections; the parameter search testing and process testing. The parameter search aims to find and justify the following parameters:
\begin{itemize}
\item Random Forest tree depth.
\item Number of training images.
\item Number of training superpixels.
\item Number of testing superpixels.
\item Regression or classification.
\end{itemize}

The process testing aimed to find following:
\begin{itemize}
\item Multi-resolution levels.
\item Morphology processes, shapes and sizes.
\end{itemize}

\subsection{Parameter Search}
All testing in the parameter search were conducted on both regression and classification types and with both 10 and 15 training images. Again the parameter search was split into two sections; to first find the Random Forest tree depth and thus use the value obtained to do the training and testing superpixel configurations.
\\[1\baselineskip]
Once the tree depth had been established, the optimal number of training superpixels was next to be justified. From there, the relationship between the number of training superpixels versus the number of testing superpixels were determined. With the optimal number of training superpixels determined for each Random Forest type and number of training images, the next step was to analyse the performance of 10 training images versus 15 for both regression and classification. The comparison between regression and classification usage was then conducted once all the prior parameters had been selected for optimal performance. 
\subsubsection{Random Forest Tree Depth}
Table \ref{table:treedepth} shows the tests that were conducted to determine the optimal Random Forest tree depth. A tree depth is selected for each regression, classification for each number of training images is selected and used for the rest of the processes.

\begin{table}[H]
\centering
\caption{Tests and variables for tree depth search.}

\begin{tabular}{|l|ll|}
\hline
\textbf{Conducted Tests}	& Random Forest type: & Regression,\\
	& 	& Classification\\		
	&  No. of Training Images: & 10, 15\\
\hline
\textbf{Controlled Variables} & No. of training superpixels: & 800 \\
	& No. of testing superpixels: & 800\\
\hline
\textbf{Independent Variables} & Random Forest tree depth: & 100, 500, 1000, 2000, 5000\\
\hline				    	 			   			    	 
\end{tabular}
\label{table:treedepth}
\end{table}

\subsubsection{Number of Training and Testing Superpixels}
The test for the optimal number of training and testing superpixels were done simultaneously. Where the test for the number of testing superpixels were done for all numbers of training superpixels. The aim of these tests were to determine the optimal number of training superpixels. From this, was to establish the relationship between the number of testing superpixels and number of training superpixels.
\begin{table}[H]
\centering
\caption{Tests and variables for number of training and testing superpixels}

\begin{tabular}{|l|ll|}
\hline
\textbf{Conducted Tests}	& Random Forest type: & Regression,\\
	& 	& Classification\\		
	&  No. of Training Images: & 10, 15\\
\hline
\textbf{Controlled Variables} & Tree depth: & 1000 \\
\hline
\textbf{Independent Variables} & No. of training superpixels: & 500, 800, 1000 \\
	& No. of testing superpixels: & 500, 800, 1000, 1500,  \\
	&	 & 2000, 2500, 3000, 3500 \\
\hline				    	 			   			    	 
\end{tabular}
\label{table:treedepth}
\end{table}

\subsection{Process Testing}
With the parameters of the model optimised and justified, the next set of tests aim to investigate the required processing during the prediction phase. This includes determining the number of testing superpixels and what levels of multi-resolution should be utilised. Once a multi-resolution process has been selected, a test between morphology processes were conducted along with the shape and sizes of the accompanied structural element. All the process testing tests were conducted on the final trained model produced from the parameter search. 

\subsubsection{Multi-Resolution}
The performance of testing superpixels had been investigated in the parameter search during the training superpixel tests. The multi-resolution tests look at the
\todo[inline]{WHAT ABOUT THRESHOLDING????}
\subsection{Morphology}
